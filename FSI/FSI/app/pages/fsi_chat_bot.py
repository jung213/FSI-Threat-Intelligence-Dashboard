import os
import re
import pandas as pd
import streamlit as st
from datetime import datetime

# LangChain / LangGraph
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOpenAI
from langgraph.graph import END, StateGraph
from typing import TypedDict

# ----------------------------
# Streamlit Page
# ----------------------------
st.set_page_config(page_title="ë³´ì•ˆ ë¼ë²¨ë§ CSV ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– ë³´ì•ˆ ë¼ë²¨ë§ CSV ì±—ë´‡")

with st.expander("ì‚¬ìš© ë°©ë²•", expanded=False):
    st.markdown("""
- `labels.csv`ë¥¼ ì—…ë¡œë“œí•˜ë©´, ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ìš”ì•½í•˜ê³  ì„¤ëª…í•´ì¤ë‹ˆë‹¤.
- ì§ˆë¬¸ ì˜ˆì‹œ:
  - `seg_scoreê°€ ë­ê³ , ë¼ë²¨ê³¼ ì–´ë–»ê²Œ ê°™ì´ ì¨ìš”?`
  - `ë¼ë²¨ True ë¹„ìœ¨ì´ë‘, ê³„ì •ë³„ í‰ê·  seg_score ìƒìœ„ 5ê°œ ì•Œë ¤ì¤˜`
  - `ì‹œê°„ëŒ€ë³„ ë¼ë²¨ True ë¹„ìœ¨ ê²½í–¥ ì„¤ëª…í•´ì¤˜`
- ëª¨ë¸: **gpt-4o-mini** (OPENAI_API_KEY í•„ìš”)
    """)

# ----------------------------
# Helpers: ë°ì´í„° ìš”ì•½/í†µê³„
# ----------------------------
RE_DATA = re.compile(r"(ë¹„ìœ¨|ìƒìœ„|í‰ê· |ë¶„í¬|ì¶”ì´|ë­í‚¹|ìˆœìœ„|count|ê±´ìˆ˜|í¼ì„¼íŠ¸|í¼ì„¼í‹°ì§€|ì¦ê°€|ê°ì†Œ)")

def _ensure_columns(df: pd.DataFrame):
    """í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ì•ˆì „í•˜ê²Œ ë³´ì •"""
    for c in ["ts","account_id","amount","seg_score","label"]:
        if c not in df.columns:
            df[c] = pd.NA
    return df

def _coerce_types(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    # ts ì‹œê°„ ë³€í™˜
    if "ts" in out.columns:
        try:
            out["ts"] = pd.to_datetime(out["ts"], errors="coerce")
        except Exception:
            pass
    # label bool ë³€í™˜
    if "label" in out.columns:
        out["label"] = out["label"].astype(str).str.lower().isin(["true","1","t","y","yes"])
    # ìˆ˜ì¹˜í˜• ë³€í™˜
    for c in ["amount","seg_score"]:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")
    return out

def summarize_df_for_prompt(df: pd.DataFrame, topn: int = 5) -> str:
    """LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ë„£ì„ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„± (ë³´ì•ˆë‹´ë‹¹ì ì¹œí™”)"""
    dff = _coerce_types(_ensure_columns(df))
    n = len(dff)
    true_rate = float(dff["label"].mean()) if n else 0.0
    avg_amt   = float(dff["amount"].mean()) if "amount" in dff else 0.0
    avg_seg   = float(dff["seg_score"].mean()) if "seg_score" in dff else 0.0

    lines = []
    lines.append(f"[ìŠ¤í‚¤ë§ˆ] columns={list(df.columns)}")
    lines.append(f"[ê¸°ë³¸] ê±´ìˆ˜={n:,}, ë¼ë²¨ True ë¹„ìœ¨={true_rate:.2%}, í‰ê·  ê¸ˆì•¡={avg_amt:,.1f}, í‰ê·  seg_score={avg_seg:.3f}")

    # ê³„ì •ë³„ í†µê³„
    if "account_id" in dff.columns:
        grp = dff.groupby("account_id").agg(
            cnt=("account_id","size"),
            true_rate=("label","mean"),
            avg_seg=("seg_score","mean"),
            avg_amt=("amount","mean"),
        ).reset_index()

        top_seg = grp.sort_values("avg_seg", ascending=False).head(topn)
        lines.append("[ê³„ì •ë³„ í‰ê·  seg_score ìƒìœ„]")
        for _, r in top_seg.iterrows():
            lines.append(f"- {r['account_id']}: avg_seg={r['avg_seg']:.3f}, cnt={int(r['cnt'])}, true_rate={r['true_rate']:.2%}")

        top_tr = grp.sort_values("true_rate", ascending=False).head(topn)
        lines.append("[ê³„ì •ë³„ ë¼ë²¨ True ë¹„ìœ¨ ìƒìœ„]")
        for _, r in top_tr.iterrows():
            lines.append(f"- {r['account_id']}: true_rate={r['true_rate']:.2%}, cnt={int(r['cnt'])}, avg_seg={r['avg_seg']:.3f}")

    # ì‹œê°„ëŒ€ ê²½í–¥
    if "ts" in dff.columns and pd.api.types.is_datetime64_any_dtype(dff["ts"]):
        dff["hour"] = dff["ts"].dt.hour
        hour_agg = dff.groupby("hour")["label"].mean().sort_index()
        if len(hour_agg) > 0:
            lines.append("[ì‹œê°„ëŒ€ë³„ ë¼ë²¨ True ë¹„ìœ¨(ê°„ì´)] " + ", ".join([f"{int(h)}ì‹œ={v:.1%}" for h, v in hour_agg.items()]))

    return "\n".join(lines)

def build_system_prompt(context_summary: str) -> str:
    return (
        "ë‹¹ì‹ ì€ ê¸ˆìœµ ë³´ì•ˆë‹´ë‹¹ìì—ê²Œ ì„¤ëª…í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì „ë¬¸ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ê³ , í•­ìƒ 'ê²°ë¡  â†’ ì´ìœ  â†’ ê¶Œê³ ' ìˆœì„œë¡œ 5~7ì¤„ í•µì‹¬ ìš”ì•½ì„ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”. "
        "ê°€ëŠ¥í•˜ë©´ ê°„ë‹¨í•œ ìˆ˜ì¹˜(%) ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”. "
        "ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¼ë²¨ CSVì˜ ìš”ì•½ì…ë‹ˆë‹¤.\n\n"
        f"{context_summary}\n\n"
        "ì„¤ëª…/ìš”ì•½ì„ ìš”ì²­í•˜ë©´ ìœ„ ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ ë‹µë³€í•˜ê³ , "
        "íŠ¹ì • í†µê³„/ìƒìœ„/ë¹„ìœ¨/í‰ê·  ë“± ë°ì´í„°í˜• ì§ˆë¬¸ì´ë©´ ë°˜ë“œì‹œ ì´ ìš”ì•½ ìˆ˜ì¹˜ë“¤ì„ ê·¼ê±°ë¡œ ì‚¼ì•„ ë‹µí•˜ì„¸ìš”."
    )

# ----------------------------
# LangGraph ìƒíƒœ & ë…¸ë“œ
# ----------------------------
class BotState(TypedDict):
    question: str
    route: str
    answer: str

def router_node(state: BotState) -> BotState:
    """ì§ˆë¬¸ì´ ë°ì´í„°í˜•ì¸ì§€(ë¹„ìœ¨/ìƒìœ„/í‰ê·  ë“±) ë˜ëŠ” ì„¤ëª…í˜•ì¸ì§€ ë¼ìš°íŒ…"""
    q = state["question"]
    route = "data" if RE_DATA.search(q) else "plain"
    return {"question": q, "route": route, "answer": ""}

def answer_plain_node(state: BotState, llm: ChatOpenAI, sys_prompt: str) -> BotState:
    prompt = ChatPromptTemplate.from_messages([
        ("system", sys_prompt),
        ("human", "{q}")
    ])
    chain = prompt | llm | StrOutputParser()
    out = chain.invoke({"q": state["question"]})
    return {"question": state["question"], "route": "plain", "answer": out}

def answer_data_node(state: BotState, llm: ChatOpenAI, sys_prompt: str) -> BotState:
    """ë°ì´í„° ì§ˆë¬¸: ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ê¹”ë”í•œ ìš´ì˜ ê´€ì  ë‹µë³€"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", sys_prompt + "\n\në°ì´í„°í˜• ì§ˆë¬¸ì´ë¯€ë¡œ ìˆ˜ì¹˜/ìˆœìœ„/ë¹„ìœ¨ì„ ìš°ì„  ì„¤ëª…í•˜ê³ , ì‹¤ë¬´ì  ê¶Œê³ ë¥¼ ë§ë¶™ì´ì„¸ìš”."),
        ("human", "{q}")
    ])
    chain = prompt | llm | StrOutputParser()
    out = chain.invoke({"q": state["question"]})
    return {"question": state["question"], "route": "data", "answer": out}

def build_graph(llm: ChatOpenAI, sys_prompt: str):
    graph = StateGraph(BotState)
    graph.add_node("router", router_node)
    # í•¨ìˆ˜í˜• ë…¸ë“œë¥¼ ê°ì‹¸ëŠ” ë˜í¼
    graph.add_node("plain", lambda s: answer_plain_node(s, llm, sys_prompt))
    graph.add_node("data",  lambda s: answer_data_node(s,  llm, sys_prompt))
    graph.set_entry_point("router")
    graph.add_conditional_edges(
        "router",
        lambda s: s["route"],
        {"plain": "plain", "data": "data"},
    )
    graph.add_edge("plain", END)
    graph.add_edge("data", END)
    return graph.compile()

# ----------------------------
# UI: íŒŒì¼ ì—…ë¡œë“œ & ì±—
# ----------------------------
uploaded = st.file_uploader("ë¼ë²¨ CSV ì—…ë¡œë“œ", type=["csv"])
if "chat_hist" not in st.session_state:
    st.session_state.chat_hist = []

if uploaded is None:
    st.info("labels.csvë¥¼ ì—…ë¡œë“œí•˜ë©´ ì±—ë´‡ì´ í™œì„±í™”ë©ë‹ˆë‹¤. (ê¶Œì¥ ì—´: ts, account_id, amount, seg_score, label)")
else:
    # CSV ì½ê¸° (ì¸ì½”ë”© ìë™ ëŒ€ì‘)
    try:
        df = pd.read_csv(uploaded)
    except Exception:
        uploaded.seek(0)
        df = pd.read_csv(uploaded, encoding="utf-8-sig")

    # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½
    context_summary = summarize_df_for_prompt(df)
    st.markdown("#### ë°ì´í„° ìš”ì•½(ìë™)")
    st.code(context_summary, language="text")

    # ëª¨ë¸ ì¤€ë¹„
    if not os.getenv("OPENAI_API_KEY"):
        st.warning("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2)

    # LangGraph ë¹Œë“œ
    sys_prompt = build_system_prompt(context_summary)
    graph = build_graph(llm, sys_prompt)

    # ì´ì „ ëŒ€í™” ë Œë”
    for role, content in st.session_state.chat_hist:
        with st.chat_message(role):
            st.write(content)

    # ì…ë ¥
    q = st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? (ì˜ˆ: ë¼ë²¨ True ë¹„ìœ¨ê³¼ ìƒìœ„ ê³„ì •ì€?)")
    if q:
        st.session_state.chat_hist.append(("user", q))
        with st.chat_message("user"):
            st.write(q)

        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                result = graph.invoke({"question": q, "route": "", "answer": ""})
                st.write(result["answer"])
        st.session_state.chat_hist.append(("assistant", result["answer"]))


from __future__ import annotations
import os, math, time
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Tuple, Dict, Set
from collections import deque

import numpy as np
import pandas as pd
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from sklearn.ensemble import IsolationForest

import streamlit as st
import plotly.express as px
import plotly.io as pio
import requests_cache

# SHAP surrogateìš©
from xgboost import XGBRegressor
import shap
import matplotlib.pyplot as plt

# ============================
# Page / Plotly theme
# ============================
st.set_page_config(page_title="FSI Threat Intel Dashboard", page_icon="ğŸ’³", layout="wide")
pio.templates.default = "simple_white"

# ============================
# Global Config & Caching
# ============================
SESSION = None
CACHE = requests_cache.CachedSession(
    cache_name="/mnt/data/fsi_ti_cache",
    backend="sqlite",
    expire_after=timedelta(minutes=30),
)

ANOMALY_ALERT_THRESHOLD = int(os.getenv("ANOMALY_ALERT_THRESHOLD", "10"))

# ============================
# Queue & Webhook Functions
# ============================
def _init_queue_state():
    if "ioc_queue" not in st.session_state:
        st.session_state["ioc_queue"] = deque()
    if "ioc_results" not in st.session_state:
        st.session_state["ioc_results"] = {}

def send_webhook(text: str, webhook_url: str) -> bool:
    if not webhook_url:
        return False
    try:
        r = requests.post(webhook_url, json={"text": text}, timeout=10)
        return r.status_code in (200, 204)
    except Exception:
        return False

def _requests_session() -> requests.Session:
    global SESSION
    if SESSION is not None:
        return SESSION
    s = requests.Session()
    retries = Retry(total=5, backoff_factor=0.4, status_forcelist=[429, 500, 502, 503, 504])
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.mount("http://", HTTPAdapter(max_retries=retries))
    SESSION = s
    return s

# ============================
# [ëª¨ë“ˆ1] ì´ìƒê±°ë˜ íƒì§€ â€” ë°ì´í„° & í”¼ì²˜
# ============================
@dataclass
class Txn:
    ts: datetime
    account_id: str
    amount: float
    country: str
    device_id: str
    ip: str
    lat: float
    lon: float

COUNTRIES = [
    ("KR", 37.5665, 126.9780),
    ("US", 40.7128, -74.0060),
    ("JP", 35.6762, 139.6503),
    ("GB", 51.5074, -0.1278),
    ("DE", 52.5200, 13.4050),
    ("IN", 28.6139, 77.2090),
]

def haversine(lat1, lon1, lat2, lon2):
    import math
    R = 6371.0
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dl = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dl/2)**2
    return 2 * R * math.asin(math.sqrt(a))

def haversine_vec(lat1, lon1, lat2, lon2):
    lat1 = lat1.astype(float).ffill().fillna(0)
    lon1 = lon1.astype(float).ffill().fillna(0)
    lat2 = lat2.astype(float).fillna(0)
    lon2 = lon2.astype(float).fillna(0)
    res = []
    for a,b,c,d in zip(lat1, lon1, lat2, lon2):
        res.append(haversine(a,b,c,d))
    return pd.Series(res)

def synth_txn_stream(n: int = 500, accounts: int = 5, seed: int = 42, use_kst: bool = False) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    rows = []
    base = datetime.utcnow() - timedelta(hours=1)
    if use_kst:
        base = base.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=9)))
    acct_ids = [f"ACCT{1000+i}" for i in range(accounts)]
    devices = [f"dev-{i}" for i in range(accounts*2)]

    for i in range(n):
        ts = base + timedelta(seconds=i*6)
        acct = rng.choice(acct_ids)
        country, lat, lon = COUNTRIES[rng.integers(0, len(COUNTRIES))]
        amount = max(0.0, float(rng.normal(85, 40)))
        if rng.random() < 0.03:
            amount *= float(rng.uniform(5, 20))
        device = rng.choice(devices)
        ip = f"{rng.integers(3, 223)}.{rng.integers(0,255)}.{rng.integers(0,255)}.{rng.integers(1,255)}"
        rows.append((ts, acct, amount, country, device, ip, lat, lon))

    df = pd.DataFrame(rows, columns=["ts","account_id","amount","country","device_id","ip","lat","lon"])
    df = df.sort_values(["account_id","ts"]).reset_index(drop=True)
    df[["prev_ts","prev_lat","prev_lon"]] = df.groupby("account_id")[['ts','lat','lon']].shift(1)
    df["gap_min"] = (df["ts"] - df["prev_ts"]).dt.total_seconds() / 60
    df["dist_km"] = haversine_vec(df["prev_lat"], df["prev_lon"], df["lat"], df["lon"])  # km
    df["speed_kmh"] = df["dist_km"] / (df["gap_min"] / 60.0)
    df.loc[df["gap_min"].isna(), ["gap_min","dist_km","speed_kmh"]] = 0
    return df

def add_seasonality_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df['ts'] = pd.to_datetime(df['ts'])
    df['dow'] = df['ts'].dt.dayofweek  # 0~6
    df['hour'] = df['ts'].dt.hour
    df['slot'] = df['dow'].astype(str) + '-' + df['hour'].astype(str)

    # ê³„ì •Ã—ìŠ¬ë¡¯ë³„ ì¤‘ì•™ê°’ baseline
    median_map = df.groupby(['account_id','slot'])['amount'].median().rename('base_amount')
    df = df.join(median_map, on=['account_id','slot'])
    df['base_amount'] = df['base_amount'].fillna(df['amount'].median())
    df['amount_resid'] = df['amount'] - df['base_amount']

    # ì‚¬ì´í´ë¦­ ì¸ì½”ë”©
    df['hour_sin'] = np.sin(2*np.pi*df['hour']/24.0)
    df['hour_cos'] = np.cos(2*np.pi*df['hour']/24.0)
    df['dow_sin']  = np.sin(2*np.pi*df['dow']/7.0)
    df['dow_cos']  = np.cos(2*np.pi*df['dow']/7.0)
    return df

# ============================
# [ëª¨ë“ˆ1] ì„¸ë¶„í™” ëª¨ë¸ (ìƒìœ„ Nê³„ì • ì „ìš© + ê³µìš©)
# ============================
FEATURES_IFOREST = ['amount_resid','gap_min','dist_km','speed_kmh','hour_sin','hour_cos','dow_sin','dow_cos']

def top_accounts(df: pd.DataFrame, top_n: int = 3):
    counts = df['account_id'].value_counts()
    return set(counts.head(top_n).index)

def fit_isoforest_segmented(df: pd.DataFrame, contamination: float = 0.03, top_n: int = 3):
    models: dict[tuple, IsolationForest] = {}
    tops = top_accounts(df, top_n)
    # ê³„ì • ì „ìš©
    for acct in tops:
        sub = df[df['account_id'] == acct]
        X = sub[FEATURES_IFOREST].fillna(0)
        iso = IsolationForest(n_estimators=200, contamination=contamination, random_state=7, n_jobs=-1)
        iso.fit(X)
        models[('acct', acct)] = iso
    # ë‚˜ë¨¸ì§€ ê³µìš©
    rest = df[~df['account_id'].isin(tops)]
    Xr = rest[FEATURES_IFOREST].fillna(0)
    iso_rest = IsolationForest(n_estimators=200, contamination=contamination, random_state=7, n_jobs=-1)
    iso_rest.fit(Xr)
    models[('global','rest')] = iso_rest
    return models, tops

def score_segmented(models: dict, tops: set, row: pd.Series) -> float:
    key = ('acct', row['account_id']) if row['account_id'] in tops else ('global','rest')
    iso = models[key]
    # DataFrameìœ¼ë¡œ ë„£ì–´ feature name ì¼ì¹˜ â†’ sklearn ê²½ê³  ì œê±°
    x_df = pd.DataFrame([[row[c] for c in FEATURES_IFOREST]], columns=FEATURES_IFOREST)
    return float(-iso.score_samples(x_df)[0])  # ë†’ì„ìˆ˜ë¡ ì´ìƒì¹˜

# ============================
# [ëª¨ë“ˆ2] ìœ„í˜‘ ì¸í…” (VirusTotalë§Œ)
# ============================
VT_BASE = "https://www.virustotal.com/api/v3"

def get_secret(name: str, env_name: str | None = None, default: str | None = None) -> str | None:
    try:
        if name in st.secrets:
            return st.secrets.get(name)
    except Exception:
        pass
    if env_name:
        val = os.getenv(env_name)
        if val:
            return val
    return default

def vt_scan_url(url: str, api_key: str) -> str | None:
    if not api_key:
        return None
    s = _requests_session()
    resp = s.post(
        f"{VT_BASE}/urls",
        headers={"x-apikey": api_key},
        data={"url": url},
        timeout=20,
    )
    if resp.status_code in (200, 202):
        try:
            return resp.json()["data"]["id"]
        except Exception:
            return None
    return None

def vt_get_analysis(analysis_id: str, api_key: str) -> dict | None:
    if not api_key or not analysis_id:
        return None
    s = _requests_session()
    r = s.get(f"{VT_BASE}/analyses/{analysis_id}", headers={"x-apikey": api_key}, timeout=20)
    if r.status_code == 200:
        return r.json()
    return None

# ============================
# [ëª¨ë“ˆ3] SHAP surrogate (XGBoost)
# ============================
SURR_FEATURES = FEATURES_IFOREST

def train_shap_surrogate(df: pd.DataFrame, target_col: str = 'seg_score'):
    # í‘œë³¸ ì¶”ì¶œ(ì†ë„ ìœ„í•´)
    sample = df.sample(n=min(len(df), 500), random_state=7)
    X = sample[SURR_FEATURES].fillna(0)
    y = sample[target_col].values

    reg = XGBRegressor(
        n_estimators=300,
        max_depth=4,
        learning_rate=0.06,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=7,
        n_jobs=-1,
    )
    reg.fit(X, y)
    explainer = shap.TreeExplainer(reg)
    shap_values = explainer(X)
    return reg, explainer, shap_values, sample

# ============================
# Labeling UI (save to data/labels.csv)
# ============================
def labeling_ui(df_top_alerts: pd.DataFrame):
    here = Path(__file__).resolve()
    project_root = (here.parent.parent if here.parent.name.lower()=="app" else here.parent)
    data_dir = project_root / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    label_path = data_dir / "labels.csv"

    base = df_top_alerts[['ts','account_id','amount','seg_score']].copy()
    base["label"] = False
    if "label_editor_df" not in st.session_state:
        st.session_state["label_editor_df"] = base

    edited = st.data_editor(
        st.session_state["label_editor_df"],
        num_rows="dynamic",
        use_container_width=True,
        key="label_editor",
    )
    st.session_state["label_editor_df"] = edited

    c1,c2 = st.columns([1,1])
    with c1:
        if st.button("ë¼ë²¨ ì €ì¥", type="primary", use_container_width=True):
            try:
                cols = [c for c in ["ts","account_id","amount","seg_score","label"] if c in edited.columns]
                if not cols:
                    st.error("ì €ì¥í•  ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return
                save = edited[cols].copy()
                if label_path.exists():
                    prev = pd.read_csv(label_path)
                    save = pd.concat([prev, save], ignore_index=True)
                save.to_csv(label_path, index=False, encoding="utf-8-sig")
                st.success(f"Saved to {label_path}")
                csv_bytes = save.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
                st.download_button("labels.csv ë‹¤ìš´ë¡œë“œ", data=csv_bytes, file_name="labels.csv", mime="text/csv", use_container_width=True)
            except Exception as e:
                st.exception(e)
    with c2:
        with st.expander("ê²½ë¡œ/í™˜ê²½ ë””ë²„ê·¸"):
            st.write({"cwd": str(Path.cwd()), "label_path": str(label_path)})

# ============================
# Live Mode Functions
# ============================
def _init_live_state(init_rows: int, use_kst: bool):
    if "live_df" not in st.session_state:
        base_df = synth_txn_stream(init_rows, use_kst=use_kst)
        st.session_state.live_df = base_df.copy()
        st.session_state.last_ts = base_df["ts"].max()
        st.session_state.tick = 0

def _append_new_tx(n_new: int):
    df = st.session_state.live_df
    last_ts = st.session_state.last_ts
    rng = np.random.default_rng(int(time.time()))
    acct_ids = df["account_id"].unique().tolist()
    devices = df["device_id"].unique().tolist()
    rows = []
    for i in range(n_new):
        ts = last_ts + timedelta(seconds=6*(i+1))
        acct = rng.choice(acct_ids)
        country, lat, lon = COUNTRIES[rng.integers(0, len(COUNTRIES))]
        amount = max(0.0, float(rng.normal(85, 40)))
        if rng.random() < 0.03:
            amount *= float(rng.uniform(5, 20))
        device = rng.choice(devices)
        ip = f"{rng.integers(3,223)}.{rng.integers(0,255)}.{rng.integers(0,255)}.{rng.integers(1,255)}"
        rows.append((ts, acct, amount, country, device, ip, lat, lon))
    new_df = pd.DataFrame(rows, columns=["ts","account_id","amount","country","device_id","ip","lat","lon"])
    out = pd.concat([df, new_df], ignore_index=True).sort_values(["account_id","ts"]).reset_index(drop=True)
    out[["prev_ts","prev_lat","prev_lon"]] = out.groupby("account_id")[['ts','lat','lon']].shift(1)
    out["gap_min"] = (out["ts"] - out["prev_ts"]).dt.total_seconds() / 60
    out["dist_km"] = haversine_vec(out["prev_lat"], out["prev_lon"], out["lat"], out["lon"])
    out["speed_kmh"] = out["dist_km"] / (out["gap_min"] / 60.0)
    out.loc[out["gap_min"].isna(), ["gap_min","dist_km","speed_kmh"]] = 0
    st.session_state.live_df = out
    st.session_state.last_ts = out["ts"].max()
    st.session_state.tick = st.session_state.get("tick", 0) + 1

# ============================
# Sidebar (Combined from test1.py + test2.py)
# ============================
with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    
    # ì‹œê°„ëŒ€ ì˜µì…˜ (test2.pyì—ì„œ)
    use_kst = st.toggle("ğŸ•’ KST(UTC+9) íƒ€ì„ìŠ¤íƒ¬í”„ ì‚¬ìš©", value=False, key="use_kst")
    
    # Live ëª¨ë“œ ì„¤ì • (test2.pyì—ì„œ)
    live_mode = st.toggle("ğŸ”´ Live ëª¨ë“œ", value=False, key="live_mode")
    refresh_sec = st.number_input("ê°±ì‹  ì£¼ê¸°(ì´ˆ)", 1, 60, 3, key="refresh_sec")
    new_per_tick = st.number_input("í‹±ë‹¹ ì‹ ê·œ ê±°ë˜ ìˆ˜", 1, 200, 20, key="new_per_tick")
    window_rows = st.number_input("í•™ìŠµìš© ìµœê·¼ ìƒ˜í”Œ ìˆ˜", 200, 5000, 1200, key="window_rows")
    
    st.markdown("---")
    
    # API Key ë° ê¸°ë³¸ ì„¤ì •
    VT_KEY = st.text_input("VirusTotal API Key", 
                           value=os.getenv("VIRUSTOTAL_API_KEY", st.secrets.get("VT_API_KEY", "") if "VT_API_KEY" in st.secrets else ""),
                           type="password", key="vt_api_key")
    n_rows = st.slider("ê±°ë˜ ìƒì„±ëŸ‰", 200, 2000, 600, step=100, key="init_rows")
    contam = st.slider("IF ì´ìƒì¹˜ ë¹„ìœ¨", 0.01, 0.10, 0.03, step=0.01, key="contamination")
    top_n = st.slider("ì „ìš© ëª¨ë¸ ê³„ì • ìˆ˜", 1, 5, 3, key="topn_accounts")
    
    st.caption("API í‚¤ê°€ ì—†ìœ¼ë©´ VT ì¡°íšŒëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")

    # ì±—ë´‡ ì¹´ë“œ (test1.pyì—ì„œ)
    st.markdown("---")
    st.subheader("ğŸ¤– ì±—ë´‡")
    try:
        st.page_link(
            "pages/fsi_chat_bot.py",
            label="ë³´ì•ˆ ì±—ë´‡ ì—´ê¸°",
            icon=":material/smart_toy:"
        )
    except Exception:
        if st.button("ğŸ¤– ë³´ì•ˆ ì±—ë´‡ ì—´ê¸°", use_container_width=True):
            st.switch_page("pages/fsi_chat_bot.py")

    # ì‚¬ìš© íŒ
    with st.expander("â„¹ï¸ ì‚¬ìš© íŒ"):
        st.markdown("""
        - **Live ëª¨ë“œ ON** â†’ ì•„ë˜ Tick ì¹´ìš´íŠ¸ê°€ ì¦ê°€í•´ì•¼ ì •ìƒ
        - **ê°±ì‹  ì£¼ê¸°**: ë„ˆë¬´ ë¹ ë¥´ë©´ 3~5ì´ˆë¡œ, ëŠë¦¬ë©´ 1~2ì´ˆë¡œ ì¡°ì •
        - **API í‚¤**: VirusTotal API í‚¤ê°€ ì—†ìœ¼ë©´ VT ì¡°íšŒëŠ” ê±´ë„ˆëœë‹ˆë‹¤
        - **Slack ì•Œë¦¼**: ALERT_WEBHOOK_URL í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‹œ ì´ìƒê±°ë˜ ì•Œë¦¼
        """)

# ============================
# Header
# ============================
st.title("ğŸ’³ FSI Threat Intelligence Dashboard")
st.caption("ì´ìƒê±°ë˜ íƒì§€ Â· VirusTotal Â· SHAP Â· ë¼ë²¨ë§ Â· Live ëª¨ë“œ Â· Slack ì•Œë¦¼")

# ============================
# Pipeline (data â†’ features â†’ model)
# ============================
# ë°ì´í„° ì¤€ë¹„ (ë¼ì´ë¸Œ ëª¨ë“œë©´ ì„¸ì…˜ ëˆ„ì  ì‚¬ìš©)
if live_mode:
    _init_live_state(n_rows, use_kst)
    _append_new_tx(int(new_per_tick))
    raw = st.session_state.live_df.tail(int(window_rows)).copy()  # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
    feat = add_seasonality_features(raw)  # ìºì‹œ ìš°íšŒ (í•­ìƒ ìµœì‹  ë°˜ì˜)
else:
    raw = synth_txn_stream(n_rows, use_kst=use_kst)
    feat = add_seasonality_features(raw)

models, tops = fit_isoforest_segmented(feat, contam, top_n)

# ì„¸ë¶„í™” ìŠ¤ì½”ì–´ ê³„ì‚°
feat['seg_score'] = feat.apply(lambda r: score_segmented(models, tops, r), axis=1)
thr_global = float(np.quantile(feat['seg_score'], 0.97))
feat['is_anomaly'] = (feat['seg_score'] >= thr_global).astype(int)

# ============================
# KPI
# ============================
total = len(feat)
anoms = int(feat['is_anomaly'].sum())
avg_amt = float(feat['amount'].mean())
fast_mv = int((feat['speed_kmh'] > 900).sum())
tick_count = st.session_state.get("tick", 0) if live_mode else 0

k1, k2, k3, k4, k5 = st.columns(5)
with k1: st.metric("ê±°ë˜ ì´ìˆ˜", f"{total:,}")
with k2: st.metric("ì´ìƒ íƒì§€ ê±´ìˆ˜", anoms)
with k3: st.metric("í‰ê·  ê±°ë˜ê¸ˆì•¡", f"â‚© {avg_amt:,.0f}")
with k4: st.metric("ê³ ì† ì´ë™ ì´ë²¤íŠ¸(>900km/h)", fast_mv)
with k5: st.metric("Live Tick", tick_count)

# ============================
# ì´ìƒê±°ë˜ ëŒ€ì‹œë³´ë“œ
# ============================
st.subheader("ğŸ“Š ì´ìƒê±°ë˜ íƒì§€ ")
fig = px.line(feat.sort_values('ts'), x='ts', y='amount', color='is_anomaly', markers=False)
st.plotly_chart(fig, use_container_width=True)
st.caption("ë¹¨ê°„ ë²”ë¡€(1)ëŠ” ì´ìƒì¹˜ë¡œ ê°„ì£¼ëœ ê±°ë˜ â€” ëª¨ë¸: ìƒìœ„ ê³„ì • ì „ìš© + ê³µìš©")

topN = st.slider("ë¼ë²¨ë§ ëŒ€ìƒ ìƒìœ„ N", 10, 200, 50)
top_alerts = feat.sort_values('seg_score', ascending=False).head(topN)[[
    'ts','account_id','amount','amount_resid','country','ip','gap_min','dist_km','speed_kmh','seg_score','is_anomaly'
]]
st.dataframe(top_alerts, use_container_width=True, height=360)

# ============================
# VirusTotal + SHAP (two columns)
# ============================
left, right = st.columns([1.15, 1.0])

with left:
    st.subheader("ğŸ›°ï¸ VirusTotal URL ë¶„ì„")
    url_ioc = st.text_input("IOC URL", placeholder="https://...", key="ioc_url")
    if st.button("VirusTotal ì¡°íšŒ", type="primary"):
        if not VT_KEY:
            st.warning("API Keyê°€ ì—†ì–´ VT ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            with st.spinner("VirusTotal ì¡°íšŒ ì¤‘..."):
                vt_id = vt_scan_url(url_ioc, VT_KEY)
                vt_res = vt_get_analysis(vt_id, VT_KEY) if vt_id else None
            if vt_res:
                try:
                    attr = vt_res.get("data", {}).get("attributes", {})
                    stats = attr.get("stats", {}) or attr.get("last_analysis_stats", {})
                    st.json(stats)
                except Exception:
                    st.json(vt_res)
            else:
                st.warning("VT ê²°ê³¼ ì—†ìŒ (í‚¤ ëˆ„ë½/ë ˆì´íŠ¸ë¦¬ë°‹/ë¶„ì„ ëŒ€ê¸° ê°€ëŠ¥)")

with right:
    st.subheader("ğŸ” SHAP ë¶„ì„")
    st.caption("IF ì ìˆ˜ë¥¼ XGBoostë¡œ ê·¼ì‚¬í•˜ì—¬ SHAPë¡œ ì„¤ëª…")
    if st.button("SHAP ì‹¤í–‰"):
        with st.spinner("SHAP ê³„ì‚° ì¤‘..."):
            reg, explainer, shap_values, sample = train_shap_surrogate(feat, target_col='seg_score')
        # ìš”ì•½ ë°”
        fig1 = plt.figure(figsize=(6, 4))
        try:
            shap.summary_plot(shap_values, features=sample[SURR_FEATURES], feature_names=SURR_FEATURES, plot_type="bar", show=False)
        except Exception:
            shap.summary_plot(shap_values.values, features=sample[SURR_FEATURES], feature_names=SURR_FEATURES, plot_type="bar", show=False)
        st.pyplot(fig1, bbox_inches='tight', pad_inches=0.1)

# ============================
# Slack ì•Œë¦¼ (ì´ìƒ ê±´ìˆ˜ ì„ê³„)
# ============================
_init_queue_state()  # st.session_state ì‚¬ìš© ì‹œ ì•ˆì „

# ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ìš©: 15ë¶„ ì¿¨ë‹¤ìš´
COOLDOWN_SEC = 15 * 60
now = datetime.utcnow()
last_sent = st.session_state.get("last_anomaly_alert_at")
ALERT_WEBHOOK = get_secret("ALERT_WEBHOOK_URL", "ALERT_WEBHOOK_URL", None)

if ALERT_WEBHOOK and anoms >= ANOMALY_ALERT_THRESHOLD:
    should_send = (last_sent is None) or ((now - last_sent).total_seconds() > COOLDOWN_SEC)
    if should_send:
        msg = (
            f":rotating_light: ì´ìƒê±°ë˜ ê²½ë³´\n"
            f"- íƒì§€ ê±´ìˆ˜: *{anoms}* (ì„ê³„ {ANOMALY_ALERT_THRESHOLD}+)\n"
            f"- ìƒ˜í”Œ: ìƒìœ„ 3ê±´ ê³„ì •/ê¸ˆì•¡\n"
        )
        try:
            top3 = (
                feat.loc[feat["is_anomaly"] == 1, ["account_id", "amount", "seg_score"]]
                .sort_values("seg_score", ascending=False)
                .head(3)
            )
            lines = [
                f"  â€¢ {r.account_id} â€” â‚©{r.amount:,.0f} (score={r.seg_score:.3f})" for r in top3.itertuples()
            ]
            msg += "\n".join(lines) if lines else "  â€¢ (í‘œì‹œí•  ìƒ˜í”Œ ì—†ìŒ)"
        except Exception:
            pass

        if send_webhook(msg, ALERT_WEBHOOK):
            st.session_state["last_anomaly_alert_at"] = now
            st.success(f"Slack ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ! (ì´ìƒê±°ë˜ {anoms}ê±´)")

# ============================
# ë¼ë²¨ë§ UI
# ============================
st.subheader("ğŸ·ï¸ ë¼ë²¨ë§")
st.caption("íƒì§€ ìƒìœ„ ê±´ì„ ìˆ˜ë™ ë¼ë²¨ë§í•˜ì—¬ ì§€ë„í•™ìŠµì— í™œìš©")
labeling_ui(top_alerts)

# ============================
# Footer
# ============================
st.markdown("---")
st.markdown("â“’ 2025 ê¸ˆìœµë³´ì•ˆì•„ì¹´ë°ë¯¸ â€¢ FDS/SIEM ë°ëª¨ â€¢ í†µí•© ë²„ì „ (test1 + test2)")

# ============================
# Live auto refresh (sleep + rerun)
# ============================
if live_mode:
    tz = timezone(timedelta(hours=9)) if use_kst else timezone.utc
    st.caption(f"â±ï¸ Live Tick: {st.session_state.get('tick',0)} Â· ìµœê·¼ ìƒ˜í”Œ: {len(feat):,} ê±´ Â· TZ={'KST' if use_kst else 'UTC'} Â· ë§ˆì§€ë§‰ ê°±ì‹ : {datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')}")
    time.sleep(float(refresh_sec))
    st.rerun()